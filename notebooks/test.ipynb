{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerold/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from gpt2.model import GPT2, CausalSelfAttention, Block\n",
    "from gpt2.trainer import Trainer\n",
    "from gpt2.config import GPT2Config, TrainerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://img.shields.io/badge/Open%20in%20Colab-Notebook-orange?logo=google-colab)](https://colab.research.google.com/github/your_username/your_repository/blob/master/path/to/your_notebook.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = GPT2Config(n_layer=4, d_model=64, n_ctx=24, n_head=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset openwebtext10k (/home/gerold/.cache/huggingface/datasets/stas___openwebtext10k/plain_text/1.0.0/3a8df094c671b4cb63ed0b41f40fb3bd855e9ce2e3765e5df50abcdfb5ec144b)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"stas/openwebtext-10k\"\n",
    "name = 'data/' + dataset_name.split('/')[-1]\n",
    "ds = load_dataset(dataset_name, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerold/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "sample = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_x = tokenizer(\n",
    "    sample['text'], return_tensors='pt',\n",
    "    return_attention_mask=False,\n",
    "    max_length=conf.n_ctx,\n",
    "     padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_x['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50257, 64)\n",
      "Embedding(24, 64)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=8, out_features=64, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "CausalSelfAttention(\n",
      "  (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=64, out_features=3072, bias=True)\n",
      "Linear(in_features=3072, out_features=64, bias=True)\n",
      "GELU(approximate='none')\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (act): GELU(approximate='none')\n",
      ")\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Block(\n",
      "  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): CausalSelfAttention(\n",
      "    (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "  )\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=8, out_features=64, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "CausalSelfAttention(\n",
      "  (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=64, out_features=3072, bias=True)\n",
      "Linear(in_features=3072, out_features=64, bias=True)\n",
      "GELU(approximate='none')\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (act): GELU(approximate='none')\n",
      ")\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Block(\n",
      "  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): CausalSelfAttention(\n",
      "    (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "  )\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=8, out_features=64, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "CausalSelfAttention(\n",
      "  (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=64, out_features=3072, bias=True)\n",
      "Linear(in_features=3072, out_features=64, bias=True)\n",
      "GELU(approximate='none')\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (act): GELU(approximate='none')\n",
      ")\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Block(\n",
      "  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): CausalSelfAttention(\n",
      "    (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "  )\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=8, out_features=64, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "CausalSelfAttention(\n",
      "  (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=64, out_features=3072, bias=True)\n",
      "Linear(in_features=3072, out_features=64, bias=True)\n",
      "GELU(approximate='none')\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (act): GELU(approximate='none')\n",
      ")\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Block(\n",
      "  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): CausalSelfAttention(\n",
      "    (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "  )\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Block(\n",
      "    (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): CausalSelfAttention(\n",
      "      (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "      (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): Block(\n",
      "    (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): CausalSelfAttention(\n",
      "      (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "      (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): Block(\n",
      "    (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): CausalSelfAttention(\n",
      "      (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "      (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (3): Block(\n",
      "    (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): CausalSelfAttention(\n",
      "      (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "      (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=64, out_features=50257, bias=True)\n",
      "GPT2(\n",
      "  (embedding): Embedding(50257, 64)\n",
      "  (pos_embedding): Embedding(24, 64)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=64, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=64, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (unembed): Linear(in_features=64, out_features=50257, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GPT2(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 8,123,473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8123473"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(in_x['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 50257])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_conf = TrainerConfig(ckpt_path='../ckpt', log_path='../logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainer_conf, model, loader, loader, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ckpt/2023-30-2700:30:28 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12739/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/gpt2-all-in/gpt2/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     t.save(self.model.state_dict(),\n\u001b[0m\u001b[1;32m     75\u001b[0m                            f\"{self.ckpt_path}/step-{step}.pt\")\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ckpt/2023-30-2700:30:28 does not exist."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.82490511970208"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = t.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 23])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_x['input_ids'][:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 23])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_x['input_ids'][:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 23, 50257])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 50257])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logits[:, :-1].reshape(-1, 50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = in_x['input_ids'][:, 1:].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9579, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.3116e-01, -4.0233e-01, -8.4505e-01,  ...,  6.8999e-01,\n",
       "           3.6214e-01,  1.5408e+00],\n",
       "         [ 4.6434e-01,  1.9396e-01, -6.1156e-01,  ...,  6.8430e-01,\n",
       "           5.2703e-01,  1.0217e+00],\n",
       "         [ 2.2291e-01, -4.4124e-01, -1.7862e-02,  ...,  1.1990e+00,\n",
       "           4.5777e-01,  7.8050e-01],\n",
       "         ...,\n",
       "         [ 5.6607e-01,  2.8459e-01, -2.1476e-01,  ...,  8.6783e-01,\n",
       "           4.9642e-01,  7.7099e-01],\n",
       "         [ 3.4211e-01,  2.3933e-01,  3.8665e-01,  ...,  1.0125e+00,\n",
       "           5.9718e-01,  1.1299e+00],\n",
       "         [ 6.4597e-01,  1.8843e-01, -5.6215e-01,  ...,  3.4234e-01,\n",
       "           6.4102e-01,  1.3953e+00]],\n",
       "\n",
       "        [[ 6.4040e-01, -1.9757e-01, -2.4741e-01,  ...,  7.8582e-01,\n",
       "           4.0753e-01,  1.3126e+00],\n",
       "         [ 2.3055e-01,  1.4652e-01, -5.4134e-02,  ...,  8.4779e-01,\n",
       "          -1.5070e-01,  1.2744e+00],\n",
       "         [ 4.0272e-01, -3.9435e-01, -1.3298e-01,  ...,  1.1853e+00,\n",
       "           7.0849e-02,  1.7149e+00],\n",
       "         ...,\n",
       "         [ 4.9057e-01,  1.3893e-02, -6.1697e-02,  ...,  9.7285e-01,\n",
       "           2.5293e-01,  1.1577e+00],\n",
       "         [ 3.7825e-01, -7.1742e-02, -7.5467e-02,  ...,  7.7197e-01,\n",
       "           4.3317e-01,  8.7201e-01],\n",
       "         [ 6.1946e-01,  1.9486e-01, -7.7523e-03,  ...,  6.6454e-01,\n",
       "           9.5669e-01,  1.2634e+00]],\n",
       "\n",
       "        [[ 3.7777e-01,  3.7281e-01, -5.3123e-01,  ...,  4.3572e-01,\n",
       "           2.9465e-01,  1.2967e+00],\n",
       "         [ 2.1721e-01,  7.0376e-02, -6.1661e-01,  ...,  5.9218e-01,\n",
       "           9.8796e-02,  1.2160e+00],\n",
       "         [ 1.0551e-01, -1.1190e-03, -6.7322e-01,  ...,  7.8625e-01,\n",
       "           1.3344e-01,  1.3070e+00],\n",
       "         ...,\n",
       "         [ 2.8574e-01, -6.0360e-02, -7.5324e-02,  ...,  5.1648e-01,\n",
       "           9.7751e-02,  1.0194e+00],\n",
       "         [-1.1144e-02, -9.2419e-02, -1.0876e-02,  ...,  1.0773e+00,\n",
       "           3.2118e-01,  1.1263e+00],\n",
       "         [ 6.2307e-01, -1.3258e-01, -4.7254e-01,  ...,  1.2762e+00,\n",
       "           4.1532e-01,  6.9063e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.3706e-01, -3.4504e-01, -4.6429e-01,  ...,  4.5105e-01,\n",
       "           2.3650e-01,  1.3035e+00],\n",
       "         [ 9.5062e-01,  1.4076e-01, -8.8031e-02,  ...,  6.6512e-01,\n",
       "           2.0612e-01,  1.5819e+00],\n",
       "         [ 1.5841e-01, -4.9453e-01, -7.5897e-01,  ...,  1.0484e+00,\n",
       "          -1.1981e-01,  1.0477e+00],\n",
       "         ...,\n",
       "         [ 3.2698e-01,  8.9749e-02, -4.2440e-01,  ...,  8.5519e-01,\n",
       "           2.7510e-01,  8.3228e-01],\n",
       "         [ 3.7947e-01,  6.7283e-02,  1.3996e-01,  ...,  1.1209e+00,\n",
       "           2.8826e-01,  1.5112e+00],\n",
       "         [ 3.6822e-01, -3.6345e-01,  1.0801e-01,  ...,  6.6650e-01,\n",
       "           5.9814e-01,  7.2802e-01]],\n",
       "\n",
       "        [[ 4.2675e-01, -5.3367e-02, -7.7424e-01,  ...,  4.9090e-01,\n",
       "           2.4339e-01,  1.0935e+00],\n",
       "         [ 8.4519e-01,  2.2953e-01, -4.3680e-01,  ...,  3.8839e-01,\n",
       "           1.9774e-01,  1.3086e+00],\n",
       "         [ 4.5433e-01, -5.0432e-01, -5.3470e-01,  ...,  6.4082e-01,\n",
       "           8.1438e-02,  1.2704e+00],\n",
       "         ...,\n",
       "         [ 1.6030e-01, -1.9519e-01, -7.2243e-01,  ...,  4.1638e-01,\n",
       "           7.0243e-01,  1.1142e+00],\n",
       "         [ 6.9805e-01,  2.7959e-01, -2.5397e-01,  ...,  9.5813e-01,\n",
       "           4.9319e-01,  1.0614e+00],\n",
       "         [ 8.1914e-01,  1.3756e-01, -3.2717e-01,  ...,  4.0661e-01,\n",
       "           5.8565e-01,  8.1239e-01]],\n",
       "\n",
       "        [[ 3.3488e-01, -4.3149e-01, -9.2275e-01,  ...,  6.0017e-01,\n",
       "          -3.0940e-01,  1.2579e+00],\n",
       "         [ 1.8303e-01, -2.1219e-01, -3.5576e-01,  ...,  7.3728e-01,\n",
       "           2.1530e-01,  1.1922e+00],\n",
       "         [ 4.4467e-01, -2.5883e-01, -3.4840e-02,  ...,  1.1238e+00,\n",
       "           4.6040e-01,  1.5677e+00],\n",
       "         ...,\n",
       "         [ 2.9676e-02, -4.9989e-02,  9.3677e-02,  ...,  5.4245e-01,\n",
       "           1.8773e-01,  1.0886e+00],\n",
       "         [ 5.0083e-01, -1.5688e-01, -2.0130e-01,  ...,  6.9607e-01,\n",
       "           9.2834e-02,  1.8074e+00],\n",
       "         [ 8.7584e-01,  1.4190e-01, -4.2863e-02,  ...,  3.7664e-01,\n",
       "           5.2096e-01,  1.0830e+00]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GPT2Tokenizer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79749/2772122730.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_sequences\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GPT2Tokenizer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "BatchEncoding(data=sample, encoding=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenizer(ds[0]['text'], return_tensors='pt', return_attention_mask=False, max_length=CONTEXT_LENGTH, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2(GPT2Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(sample['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3097,  0.4870,  0.6961,  ...,  0.5891, -0.4094,  0.4599],\n",
       "         [ 0.5984,  0.6257,  0.1372,  ...,  0.5681,  0.3522,  0.5912],\n",
       "         [ 0.1387,  0.5918,  0.5854,  ...,  0.4782,  0.6790,  0.5634],\n",
       "         ...,\n",
       "         [ 0.5673,  0.1265, -0.0827,  ...,  0.2595,  0.7240,  0.4301],\n",
       "         [ 0.4464,  0.5339, -0.3811,  ...,  0.3145,  0.7945,  0.1410],\n",
       "         [ 0.8457,  0.3049,  0.1613,  ...,  0.0021,  0.4955,  0.2551]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = getattr(t.nn, 'GELU')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = act(t.Tensor([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8413, 1.9545, 2.9960])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1697, -0.0300])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = t.nn.GELU()\n",
    "input = t.randn(2)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = CausalSelfAttention(GPT2Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = Block(GPT2Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = GPT2Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(sample['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 50257])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[-8.4164, -8.4164, -8.4164,  ..., -8.4158, -8.4158, -8.4158]],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[28404, 28404, 28404,  ..., 28404, 28404, 28404]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.log_softmax(-1).max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 12, 64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4051,  1.6578, -0.1196,  ..., -1.6676, -0.5051, -2.2094],\n",
       "          [-0.2219,  0.3631,  0.1526,  ..., -1.5622,  0.9381, -0.4839],\n",
       "          [ 0.1367,  0.1490,  0.2739,  ...,  0.4365,  0.0528,  0.9219],\n",
       "          ...,\n",
       "          [-0.9549, -0.4559, -1.0144,  ..., -0.9441,  0.2906,  0.0647],\n",
       "          [ 0.6279,  0.8872,  0.8348,  ..., -1.4402,  0.9681, -0.4357],\n",
       "          [ 0.0086, -0.4049, -0.5526,  ...,  0.2327, -0.0858,  1.1537]],\n",
       "\n",
       "         [[ 0.2602, -0.4546,  0.4854,  ..., -0.0907, -0.0111,  0.6941],\n",
       "          [ 0.1380,  1.3028, -0.2632,  ...,  1.1256, -0.0943, -1.3199],\n",
       "          [-0.5720, -0.1067,  1.1817,  ..., -0.3961, -0.2230,  0.2691],\n",
       "          ...,\n",
       "          [-0.5954, -0.0263, -0.7146,  ...,  0.7584,  0.6328, -2.0703],\n",
       "          [ 1.0791, -0.1267, -0.7209,  ...,  0.1225, -1.2627, -0.2249],\n",
       "          [ 0.5651, -0.7779,  0.0820,  ..., -0.9344, -0.8203, -0.7762]],\n",
       "\n",
       "         [[-0.1204, -0.4468, -0.6602,  ..., -0.9360,  0.7501,  0.2150],\n",
       "          [-1.8273, -2.4964, -1.6718,  ...,  1.5948, -1.1634, -0.5580],\n",
       "          [ 0.2756,  0.1561,  0.3570,  ...,  1.0407, -0.1844, -1.7271],\n",
       "          ...,\n",
       "          [ 0.6299, -1.0322, -0.1344,  ...,  0.1267, -0.3955, -0.0868],\n",
       "          [ 1.0936, -0.1865, -0.2938,  ..., -1.1976,  0.3846,  0.0062],\n",
       "          [-0.8897, -1.2909, -0.4578,  ...,  0.5187,  0.6053, -0.0244]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.7293, -0.5450, -0.2754,  ..., -1.3629, -0.4355, -0.9521],\n",
       "          [-0.1992,  0.8650, -0.2321,  ...,  0.0977,  0.6617, -1.5424],\n",
       "          [ 0.9756, -0.1571, -0.1756,  ..., -0.1897, -0.3623, -1.2637],\n",
       "          ...,\n",
       "          [-1.3334, -1.3384,  0.1775,  ..., -0.4491,  1.6597,  0.4902],\n",
       "          [-1.0723, -1.0327,  0.6706,  ..., -0.2070,  1.3260,  0.0941],\n",
       "          [-0.6272, -0.4252,  0.3405,  ...,  0.2230,  0.1361,  0.6276]],\n",
       "\n",
       "         [[ 0.9048,  0.1143, -0.5829,  ...,  0.9653,  1.3548, -0.3131],\n",
       "          [ 0.9944,  0.2904, -0.8118,  ..., -0.0758,  0.0291, -0.6042],\n",
       "          [-0.5268,  0.1851,  0.5841,  ..., -0.7459,  1.2706,  0.8343],\n",
       "          ...,\n",
       "          [ 1.4027, -0.4864,  0.2816,  ...,  0.5561,  0.2602,  0.2981],\n",
       "          [-1.5286,  0.9713, -0.5961,  ..., -0.4730, -0.1546,  0.5935],\n",
       "          [-0.7305,  0.4329,  0.7940,  ...,  1.5383,  0.4982,  1.1453]],\n",
       "\n",
       "         [[ 0.8508,  1.4869, -0.5775,  ...,  0.9689, -0.0661, -0.8852],\n",
       "          [ 0.2673,  1.3965,  0.3650,  ...,  0.0921,  1.2709, -0.6635],\n",
       "          [-0.0434,  0.0226, -2.4763,  ...,  1.4446,  1.0191,  1.3656],\n",
       "          ...,\n",
       "          [ 0.9066,  0.5722,  0.5326,  ..., -0.1506, -0.2596,  0.7606],\n",
       "          [-0.2697,  0.2260, -0.6846,  ...,  1.5068,  1.5467, -0.8214],\n",
       "          [ 0.3436,  0.4720, -1.1739,  ...,  0.5489,  0.9009,  0.4725]]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, n_embd, n_head = 2, 128, 64, 4\n",
    "d_head = int(n_embd / n_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.randn(batch_size, seq_len, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 4, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(batch_size, seq_len, n_head, d_head).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = a.view(batch_size, seq_len, n_head, d_head).permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = a.view(batch_size, n_head, seq_len, d_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 == out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.3545e-02, -1.9569e+00,  1.4791e+00,  ..., -9.6137e-01,\n",
       "            9.6278e-01, -2.8604e-02],\n",
       "          [-6.3019e-01,  7.8473e-01,  3.0342e-01,  ..., -9.3203e-01,\n",
       "           -7.9259e-01,  6.9010e-01],\n",
       "          [ 1.6866e+00,  2.7878e-01, -9.4930e-02,  ..., -9.5732e-01,\n",
       "           -1.2384e+00,  7.2290e-01],\n",
       "          ...,\n",
       "          [ 1.0535e+00,  8.7548e-01, -7.7688e-02,  ..., -8.7108e-01,\n",
       "           -9.5720e-02,  5.8334e-01],\n",
       "          [ 5.3082e-01,  2.8144e+00, -2.0082e-01,  ..., -1.3521e+00,\n",
       "           -2.9785e-01,  1.1507e+00],\n",
       "          [-1.3991e+00,  9.8552e-01, -5.2617e-01,  ...,  3.5328e-01,\n",
       "           -2.9659e-01,  3.6307e-01]],\n",
       "\n",
       "         [[-9.1917e-01, -2.8233e-01,  4.6615e-01,  ..., -7.5273e-01,\n",
       "            6.9479e-01, -1.0137e+00],\n",
       "          [ 1.9282e+00, -6.7646e-02,  4.4653e-01,  ...,  9.0008e-01,\n",
       "            1.0312e+00,  3.7749e-01],\n",
       "          [-8.2837e-01, -1.4259e+00, -6.0044e-01,  ..., -1.2208e+00,\n",
       "            7.8010e-01, -1.0375e+00],\n",
       "          ...,\n",
       "          [-1.7031e+00, -3.7326e-01,  2.4967e+00,  ...,  1.0366e-01,\n",
       "           -6.0204e-01, -1.2522e+00],\n",
       "          [-1.3427e+00, -2.3477e-01, -4.9436e-01,  ...,  1.6259e+00,\n",
       "           -4.9520e-01, -5.5468e-01],\n",
       "          [ 1.0514e+00, -1.6589e+00,  6.3333e-01,  ..., -5.9657e-01,\n",
       "           -6.3750e-01, -8.7127e-01]],\n",
       "\n",
       "         [[-1.3553e+00,  5.3007e-01,  1.0785e+00,  ...,  1.1081e+00,\n",
       "           -7.6913e-01,  1.5663e+00],\n",
       "          [ 4.4422e-01,  1.2420e-01, -9.0362e-02,  ..., -1.3044e+00,\n",
       "           -2.1595e+00, -2.0219e+00],\n",
       "          [ 8.6119e-01, -2.2509e+00, -1.2555e+00,  ...,  7.1268e-01,\n",
       "            4.2802e-01,  2.3750e-01],\n",
       "          ...,\n",
       "          [-7.4786e-01, -3.9436e-01, -1.5173e+00,  ...,  6.9180e-03,\n",
       "            2.3342e+00,  1.5087e+00],\n",
       "          [ 1.1416e-01, -7.7099e-01,  1.1171e+00,  ..., -4.8274e-01,\n",
       "           -4.6247e-01,  1.2646e+00],\n",
       "          [ 7.7077e-03, -2.4851e-01, -1.4579e-01,  ...,  3.0125e-01,\n",
       "            2.5172e-02,  9.9983e-01]],\n",
       "\n",
       "         [[ 8.4584e-01, -1.4190e+00,  1.6602e+00,  ..., -2.9269e-01,\n",
       "            4.4553e-02, -7.3827e-02],\n",
       "          [-8.8744e-01, -3.7377e-01, -5.5739e-01,  ...,  1.7419e+00,\n",
       "           -2.0498e+00,  9.8595e-02],\n",
       "          [ 2.1371e+00, -1.2199e+00,  6.1010e-01,  ..., -1.7225e+00,\n",
       "           -4.1101e-01, -8.0145e-02],\n",
       "          ...,\n",
       "          [ 7.3466e-01,  6.3129e-01, -7.3176e-02,  ...,  2.3345e-01,\n",
       "           -8.9799e-01, -7.7821e-01],\n",
       "          [-4.4764e-01,  1.0471e+00, -3.7919e-01,  ...,  5.2815e-01,\n",
       "           -1.3501e-01,  4.3331e-01],\n",
       "          [ 6.1764e-01, -1.1267e+00,  5.0400e-01,  ...,  2.1492e-01,\n",
       "           -9.2485e-01,  1.7607e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.5935e-01,  6.4413e-01, -3.5523e-01,  ..., -6.3059e-02,\n",
       "           -2.9291e-01, -1.5015e+00],\n",
       "          [-7.5380e-01, -3.9075e-01,  2.4201e-01,  ..., -1.0217e+00,\n",
       "           -1.3804e+00,  4.8155e-01],\n",
       "          [ 4.0471e-02, -2.9842e-01, -2.0397e-01,  ..., -5.3016e-01,\n",
       "            1.0855e+00, -7.3929e-01],\n",
       "          ...,\n",
       "          [-5.4483e-01,  1.0215e+00, -7.7667e-01,  ..., -6.3646e-01,\n",
       "           -1.7438e-01,  2.9736e-01],\n",
       "          [ 1.1071e+00,  1.2136e+00, -3.5228e-01,  ..., -7.6519e-01,\n",
       "            9.8179e-01, -1.1464e+00],\n",
       "          [-1.3171e+00, -5.5312e-01, -9.8612e-01,  ...,  1.4407e+00,\n",
       "           -1.9604e-01, -6.4454e-01]],\n",
       "\n",
       "         [[ 5.8195e-01,  1.7367e+00, -8.7589e-01,  ...,  9.5487e-02,\n",
       "           -5.2732e-01, -2.0270e-01],\n",
       "          [-2.3533e-01, -1.5872e-01,  2.3023e-01,  ..., -5.1338e-01,\n",
       "            6.0579e-01, -3.7723e-01],\n",
       "          [-6.0612e-01,  5.2375e-01,  9.7809e-01,  ...,  2.0374e+00,\n",
       "           -8.8021e-01, -6.3922e-01],\n",
       "          ...,\n",
       "          [ 5.5312e-01,  3.2313e-01, -1.8905e-02,  ..., -2.5264e-01,\n",
       "           -7.6495e-01,  9.9600e-01],\n",
       "          [ 2.2054e+00, -1.7943e+00,  1.4962e+00,  ..., -8.4421e-01,\n",
       "            1.2510e+00,  1.9214e-01],\n",
       "          [-2.2750e-01, -9.4627e-01, -1.0919e+00,  ..., -2.1551e-01,\n",
       "           -2.0516e+00, -4.8189e-01]],\n",
       "\n",
       "         [[-3.7513e-01,  1.1826e+00, -1.0837e-01,  ...,  1.1853e-01,\n",
       "            4.0080e-01,  6.8591e-01],\n",
       "          [-7.4274e-01,  2.6057e+00, -7.2578e-01,  ...,  1.8912e-01,\n",
       "            2.4812e-01, -9.0343e-01],\n",
       "          [-4.1987e-01, -1.0201e+00,  1.6111e+00,  ...,  1.6278e+00,\n",
       "           -1.3089e-01,  6.9411e-01],\n",
       "          ...,\n",
       "          [-1.0226e+00, -1.1397e+00,  1.7389e-01,  ...,  3.6806e-01,\n",
       "           -2.0649e+00, -9.0580e-01],\n",
       "          [-6.2444e-01,  1.2361e+00, -2.3314e-01,  ..., -1.7477e-01,\n",
       "           -4.4163e-01,  2.0618e+00],\n",
       "          [ 8.0082e-01,  1.2139e+00,  1.6391e+00,  ...,  1.7246e-01,\n",
       "            7.0737e-01,  1.3983e-01]],\n",
       "\n",
       "         [[-9.5327e-01, -4.0827e-01,  2.0308e+00,  ...,  9.6258e-01,\n",
       "           -1.5295e+00,  9.3559e-02],\n",
       "          [ 1.3268e+00, -3.2790e-01, -2.4710e-03,  ...,  1.1244e+00,\n",
       "            6.5715e-01, -9.4437e-01],\n",
       "          [-2.4811e+00,  1.2054e-02,  8.4120e-03,  ...,  1.3234e+00,\n",
       "           -3.9365e-01,  1.0185e+00],\n",
       "          ...,\n",
       "          [-1.5236e+00, -5.1607e-01,  8.2259e-01,  ...,  7.2664e-01,\n",
       "           -4.0363e-01,  2.4999e-01],\n",
       "          [-2.5667e-01, -9.3259e-01, -7.1804e-01,  ..., -7.3299e-01,\n",
       "           -1.9272e+00, -8.8841e-01],\n",
       "          [ 3.8090e-01,  3.7574e-01, -2.9236e-01,  ..., -1.4157e+00,\n",
       "            8.3410e-01, -8.3956e-01]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3311e+00,  4.0612e-01, -9.6838e-01,  ...,  7.6811e-01,\n",
       "            2.0105e+00, -2.4304e-01],\n",
       "          [-1.0193e-01, -8.1819e-02, -1.2097e+00,  ...,  1.8281e+00,\n",
       "           -1.5259e+00,  1.0163e+00],\n",
       "          [-1.3933e+00,  3.2227e-01,  6.7729e-01,  ...,  1.4077e+00,\n",
       "           -2.5910e+00, -1.2534e+00],\n",
       "          ...,\n",
       "          [-4.8123e-01,  8.4734e-01, -5.4851e-01,  ...,  7.2403e-01,\n",
       "            3.0951e-01, -3.4596e-01],\n",
       "          [ 8.0987e-01,  1.0177e+00, -1.0420e+00,  ..., -1.1196e+00,\n",
       "           -1.3367e+00, -4.1055e-01],\n",
       "          [ 5.3703e-01,  2.2097e+00,  1.2387e-01,  ..., -1.4005e+00,\n",
       "           -1.7899e+00,  6.4690e-01]],\n",
       "\n",
       "         [[ 5.1508e-01,  8.2310e-01, -3.0063e+00,  ...,  9.2919e-01,\n",
       "           -9.7570e-01, -8.9491e-01],\n",
       "          [ 1.6003e+00, -1.7011e+00, -2.0192e+00,  ...,  2.4410e-01,\n",
       "           -5.2997e-01,  1.1098e+00],\n",
       "          [-1.8489e+00,  1.8971e-01,  1.0997e+00,  ...,  9.3536e-01,\n",
       "            5.5458e-01,  1.8069e+00],\n",
       "          ...,\n",
       "          [-1.3856e-01, -2.9451e-01,  1.3426e+00,  ..., -4.0752e-01,\n",
       "           -1.0934e+00,  3.7895e-01],\n",
       "          [ 3.8829e-02,  1.6670e+00,  5.0474e-02,  ...,  1.5752e+00,\n",
       "           -1.3469e+00,  4.3116e-01],\n",
       "          [-3.4331e-01, -1.0998e+00,  1.2369e+00,  ...,  8.8025e-01,\n",
       "           -5.4792e-01, -3.2028e-01]],\n",
       "\n",
       "         [[ 1.0805e-01,  7.1260e-01,  2.2917e-01,  ..., -6.4505e-01,\n",
       "            8.6883e-01,  1.1445e+00],\n",
       "          [-2.3635e-01,  1.0248e+00,  1.9195e-01,  ...,  1.3236e+00,\n",
       "           -1.2498e+00,  1.7526e-01],\n",
       "          [-4.8404e-01, -2.6956e-01,  8.4039e-01,  ..., -8.3244e-01,\n",
       "            1.6855e+00,  6.3192e-01],\n",
       "          ...,\n",
       "          [ 9.7214e-03,  2.0059e-01, -1.4340e+00,  ..., -4.7506e-01,\n",
       "           -2.2128e-01, -1.7443e+00],\n",
       "          [-6.5916e-01,  3.6691e-01,  3.6858e-01,  ...,  9.6387e-01,\n",
       "            5.9490e-01, -6.9528e-01],\n",
       "          [-1.0785e+00, -7.8907e-02,  1.2839e+00,  ..., -3.5456e-01,\n",
       "           -2.9731e+00, -1.0233e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0849e+00,  5.0526e-01,  8.4190e-01,  ..., -5.7804e-01,\n",
       "           -2.4791e+00,  1.2214e+00],\n",
       "          [-1.1885e+00, -5.0756e-01,  1.3294e+00,  ..., -1.2438e+00,\n",
       "           -1.6817e+00, -1.1488e+00],\n",
       "          [-7.9743e-01,  4.8311e-01, -2.0197e-02,  ..., -1.1951e+00,\n",
       "           -1.1730e-01, -1.6711e-01],\n",
       "          ...,\n",
       "          [-1.6922e+00, -3.2976e+00, -1.4282e+00,  ...,  6.5715e-02,\n",
       "           -4.0224e-01, -1.4438e+00],\n",
       "          [ 1.4151e+00,  3.3056e-01,  7.4368e-01,  ..., -5.4170e-02,\n",
       "            1.1031e+00, -5.7785e-02],\n",
       "          [ 2.1695e-01,  1.8561e-01,  5.7949e-01,  ..., -8.4442e-01,\n",
       "           -4.9943e-01,  2.4181e+00]],\n",
       "\n",
       "         [[ 1.4676e+00, -6.9442e-01,  1.1374e+00,  ..., -6.0094e-02,\n",
       "            1.3737e+00, -3.7886e-01],\n",
       "          [-8.6492e-01,  1.0823e+00,  6.1633e-01,  ..., -1.6503e+00,\n",
       "            5.3889e-01,  7.1134e-01],\n",
       "          [ 1.6740e+00, -6.2821e-01,  1.5831e+00,  ...,  4.4199e-01,\n",
       "            1.6351e+00,  9.4814e-01],\n",
       "          ...,\n",
       "          [-1.0099e+00, -2.9612e+00,  1.7664e+00,  ..., -5.1762e-01,\n",
       "            8.7573e-01,  2.4107e-01],\n",
       "          [ 3.5522e-03, -1.5738e-01,  3.3179e-01,  ...,  2.0725e+00,\n",
       "           -7.2836e-01,  2.9003e+00],\n",
       "          [ 2.1355e-01, -1.5347e+00, -3.7773e-01,  ...,  1.7177e+00,\n",
       "            9.3784e-01,  1.0155e+00]],\n",
       "\n",
       "         [[-3.9780e-01, -5.2660e-01, -2.8048e-01,  ..., -8.7255e-01,\n",
       "           -3.1757e-01, -4.1345e-01],\n",
       "          [-2.1512e-01,  1.1361e+00,  5.9263e-01,  ..., -1.2035e-01,\n",
       "           -1.4564e+00, -2.6376e-01],\n",
       "          [-2.9571e-01, -1.3988e+00,  2.0772e-01,  ..., -2.2491e-01,\n",
       "           -2.0821e-01,  4.0366e-01],\n",
       "          ...,\n",
       "          [-3.4648e-02,  7.9535e-01,  1.7958e+00,  ...,  6.9737e-01,\n",
       "           -9.4934e-01, -7.9575e-01],\n",
       "          [-9.8324e-01,  8.7924e-03,  1.6869e+00,  ..., -6.7017e-01,\n",
       "           -1.4605e-01,  3.2390e-01],\n",
       "          [ 1.4302e-01, -6.0302e-01, -1.1850e+00,  ...,  7.9442e-02,\n",
       "           -6.9473e-02, -1.6219e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 5.8683e-01,  1.9253e+00, -1.5092e+00,  ..., -5.2852e-01,\n",
       "            2.4304e-01, -1.1935e+00],\n",
       "          [-1.2162e-01, -1.3456e+00, -5.7101e-01,  ..., -1.5827e+00,\n",
       "            7.9445e-01,  2.3423e-01],\n",
       "          [ 6.0717e-01, -7.7827e-01, -4.2541e-01,  ..., -1.1426e+00,\n",
       "            1.7688e+00,  1.4310e-01],\n",
       "          ...,\n",
       "          [ 6.8427e-01, -7.2932e-01, -7.1674e-01,  ...,  9.3921e-01,\n",
       "            2.0042e+00,  4.0428e-01],\n",
       "          [-1.5733e-01,  1.4078e-01, -5.6825e-01,  ...,  1.3454e+00,\n",
       "            3.4482e-01,  2.6986e-01],\n",
       "          [ 1.0930e-01, -8.5568e-01,  1.1881e+00,  ..., -5.6170e-01,\n",
       "           -5.7075e-01, -1.2452e+00]],\n",
       "\n",
       "         [[-1.4469e-01,  4.8896e-01,  1.3395e+00,  ..., -1.5662e-01,\n",
       "           -1.4218e+00,  2.7856e-01],\n",
       "          [-5.3405e-01, -1.6320e+00, -2.3030e-01,  ..., -1.4489e-01,\n",
       "            7.3723e-01, -5.0972e-01],\n",
       "          [-2.0008e-01, -7.9664e-01, -2.3228e+00,  ...,  2.9281e-02,\n",
       "           -3.6183e-01, -3.8916e-02],\n",
       "          ...,\n",
       "          [-2.3769e+00, -1.5477e+00, -4.7115e-01,  ...,  2.2594e+00,\n",
       "            1.1386e+00, -6.9877e-02],\n",
       "          [-2.0971e-01, -1.1470e-01, -2.2911e+00,  ..., -3.2372e-01,\n",
       "           -2.0582e+00, -1.3433e+00],\n",
       "          [ 2.2526e-02, -5.7252e-01, -6.2266e-01,  ..., -1.2715e+00,\n",
       "           -3.3840e+00, -1.8821e-01]],\n",
       "\n",
       "         [[-1.2708e-03, -2.6993e-01,  9.1102e-02,  ..., -6.1288e-01,\n",
       "            6.6199e-01,  3.2963e-01],\n",
       "          [-1.2105e+00,  1.3979e+00,  1.3573e+00,  ..., -1.7444e-01,\n",
       "            1.0963e+00, -1.3350e+00],\n",
       "          [-7.5321e-01,  1.4010e+00,  1.0393e+00,  ..., -8.6498e-01,\n",
       "           -3.7833e-01,  1.4717e+00],\n",
       "          ...,\n",
       "          [ 3.2341e-01, -1.6949e+00, -1.5267e-01,  ...,  1.0697e-01,\n",
       "           -9.2674e-01, -1.0639e+00],\n",
       "          [-1.6194e+00,  1.5367e+00, -1.0701e-01,  ...,  6.5725e-01,\n",
       "           -2.8774e-01, -1.1570e+00],\n",
       "          [ 8.7333e-01, -5.0354e-01, -6.5690e-01,  ...,  1.2375e+00,\n",
       "            4.1475e-01, -9.8938e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.5844e-01, -5.9410e-01, -1.5822e+00,  ..., -1.2397e+00,\n",
       "            3.9056e-01, -5.5074e-01],\n",
       "          [ 6.6099e-01, -8.8654e-01,  3.2603e-01,  ...,  9.6570e-01,\n",
       "           -6.6738e-01,  6.3110e-01],\n",
       "          [ 1.2920e+00,  1.7654e+00, -3.2217e-01,  ...,  1.5381e+00,\n",
       "            2.0340e+00,  2.5254e-01],\n",
       "          ...,\n",
       "          [-4.7594e-01,  2.1616e-01, -5.7696e-01,  ..., -4.8932e-02,\n",
       "            4.2493e-01,  1.8751e+00],\n",
       "          [-1.1752e-01, -1.9105e-01, -1.5669e+00,  ..., -1.0323e+00,\n",
       "            8.8574e-01,  1.5024e+00],\n",
       "          [-2.5755e-02, -1.1502e+00, -7.7229e-01,  ...,  1.8311e+00,\n",
       "           -1.5226e+00,  8.0982e-01]],\n",
       "\n",
       "         [[-1.5307e+00, -3.0179e-01,  1.1352e+00,  ..., -2.5031e-02,\n",
       "           -6.1884e-01,  1.6695e-01],\n",
       "          [-9.3179e-01,  8.9310e-01, -3.2316e-01,  ...,  5.1553e-01,\n",
       "           -6.4443e-01, -1.0090e+00],\n",
       "          [-6.3618e-01,  9.9330e-02, -1.1220e+00,  ..., -1.5260e+00,\n",
       "            1.7316e-01,  1.4391e+00],\n",
       "          ...,\n",
       "          [ 8.0673e-01,  1.2286e+00, -1.4044e+00,  ..., -2.2917e-01,\n",
       "           -5.8174e-01,  6.8764e-01],\n",
       "          [-8.0443e-01,  4.9831e-01,  1.6591e-02,  ...,  1.5389e+00,\n",
       "           -2.3523e+00, -1.5787e-01],\n",
       "          [ 6.3279e-01, -5.7257e-01,  6.0246e-01,  ..., -1.1847e+00,\n",
       "            5.7469e-01,  7.7059e-01]],\n",
       "\n",
       "         [[-5.8477e-01, -1.7205e+00,  1.6209e+00,  ...,  1.3126e+00,\n",
       "            7.5932e-01, -7.8550e-01],\n",
       "          [ 8.9837e-01, -3.5039e-01, -1.2212e-01,  ...,  9.7713e-01,\n",
       "           -8.8639e-01, -9.4984e-01],\n",
       "          [-5.8915e-01,  5.4308e-01, -9.5570e-01,  ..., -5.2155e-02,\n",
       "           -1.0870e+00, -3.4609e-01],\n",
       "          ...,\n",
       "          [-1.9298e-01, -1.6440e-01, -1.2039e+00,  ...,  1.4024e+00,\n",
       "            6.3525e-01, -2.6399e+00],\n",
       "          [-1.4343e+00, -9.9321e-01,  1.7001e+00,  ...,  5.8707e-02,\n",
       "            4.9873e-01,  1.0057e+00],\n",
       "          [-1.3849e+00,  1.7971e+00, -1.7191e+00,  ...,  6.2738e-01,\n",
       "            2.2965e-01, -5.7900e-01]]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerold/projects/gpt2-all-in/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Downloading: 100%|| 523M/523M [00:48<00:00, 11.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "pretrained = GPT2Model.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wte.weight\n",
      "wpe.weight\n",
      "h.0.ln_1.weight\n",
      "h.0.ln_1.bias\n",
      "h.0.attn.c_attn.weight\n",
      "h.0.attn.c_attn.bias\n",
      "h.0.attn.c_proj.weight\n",
      "h.0.attn.c_proj.bias\n",
      "h.0.ln_2.weight\n",
      "h.0.ln_2.bias\n",
      "h.0.mlp.c_fc.weight\n",
      "h.0.mlp.c_fc.bias\n",
      "h.0.mlp.c_proj.weight\n",
      "h.0.mlp.c_proj.bias\n",
      "h.1.ln_1.weight\n",
      "h.1.ln_1.bias\n",
      "h.1.attn.c_attn.weight\n",
      "h.1.attn.c_attn.bias\n",
      "h.1.attn.c_proj.weight\n",
      "h.1.attn.c_proj.bias\n",
      "h.1.ln_2.weight\n",
      "h.1.ln_2.bias\n",
      "h.1.mlp.c_fc.weight\n",
      "h.1.mlp.c_fc.bias\n",
      "h.1.mlp.c_proj.weight\n",
      "h.1.mlp.c_proj.bias\n",
      "h.2.ln_1.weight\n",
      "h.2.ln_1.bias\n",
      "h.2.attn.c_attn.weight\n",
      "h.2.attn.c_attn.bias\n",
      "h.2.attn.c_proj.weight\n",
      "h.2.attn.c_proj.bias\n",
      "h.2.ln_2.weight\n",
      "h.2.ln_2.bias\n",
      "h.2.mlp.c_fc.weight\n",
      "h.2.mlp.c_fc.bias\n",
      "h.2.mlp.c_proj.weight\n",
      "h.2.mlp.c_proj.bias\n",
      "h.3.ln_1.weight\n",
      "h.3.ln_1.bias\n",
      "h.3.attn.c_attn.weight\n",
      "h.3.attn.c_attn.bias\n",
      "h.3.attn.c_proj.weight\n",
      "h.3.attn.c_proj.bias\n",
      "h.3.ln_2.weight\n",
      "h.3.ln_2.bias\n",
      "h.3.mlp.c_fc.weight\n",
      "h.3.mlp.c_fc.bias\n",
      "h.3.mlp.c_proj.weight\n",
      "h.3.mlp.c_proj.bias\n",
      "h.4.ln_1.weight\n",
      "h.4.ln_1.bias\n",
      "h.4.attn.c_attn.weight\n",
      "h.4.attn.c_attn.bias\n",
      "h.4.attn.c_proj.weight\n",
      "h.4.attn.c_proj.bias\n",
      "h.4.ln_2.weight\n",
      "h.4.ln_2.bias\n",
      "h.4.mlp.c_fc.weight\n",
      "h.4.mlp.c_fc.bias\n",
      "h.4.mlp.c_proj.weight\n",
      "h.4.mlp.c_proj.bias\n",
      "h.5.ln_1.weight\n",
      "h.5.ln_1.bias\n",
      "h.5.attn.c_attn.weight\n",
      "h.5.attn.c_attn.bias\n",
      "h.5.attn.c_proj.weight\n",
      "h.5.attn.c_proj.bias\n",
      "h.5.ln_2.weight\n",
      "h.5.ln_2.bias\n",
      "h.5.mlp.c_fc.weight\n",
      "h.5.mlp.c_fc.bias\n",
      "h.5.mlp.c_proj.weight\n",
      "h.5.mlp.c_proj.bias\n",
      "h.6.ln_1.weight\n",
      "h.6.ln_1.bias\n",
      "h.6.attn.c_attn.weight\n",
      "h.6.attn.c_attn.bias\n",
      "h.6.attn.c_proj.weight\n",
      "h.6.attn.c_proj.bias\n",
      "h.6.ln_2.weight\n",
      "h.6.ln_2.bias\n",
      "h.6.mlp.c_fc.weight\n",
      "h.6.mlp.c_fc.bias\n",
      "h.6.mlp.c_proj.weight\n",
      "h.6.mlp.c_proj.bias\n",
      "h.7.ln_1.weight\n",
      "h.7.ln_1.bias\n",
      "h.7.attn.c_attn.weight\n",
      "h.7.attn.c_attn.bias\n",
      "h.7.attn.c_proj.weight\n",
      "h.7.attn.c_proj.bias\n",
      "h.7.ln_2.weight\n",
      "h.7.ln_2.bias\n",
      "h.7.mlp.c_fc.weight\n",
      "h.7.mlp.c_fc.bias\n",
      "h.7.mlp.c_proj.weight\n",
      "h.7.mlp.c_proj.bias\n",
      "h.8.ln_1.weight\n",
      "h.8.ln_1.bias\n",
      "h.8.attn.c_attn.weight\n",
      "h.8.attn.c_attn.bias\n",
      "h.8.attn.c_proj.weight\n",
      "h.8.attn.c_proj.bias\n",
      "h.8.ln_2.weight\n",
      "h.8.ln_2.bias\n",
      "h.8.mlp.c_fc.weight\n",
      "h.8.mlp.c_fc.bias\n",
      "h.8.mlp.c_proj.weight\n",
      "h.8.mlp.c_proj.bias\n",
      "h.9.ln_1.weight\n",
      "h.9.ln_1.bias\n",
      "h.9.attn.c_attn.weight\n",
      "h.9.attn.c_attn.bias\n",
      "h.9.attn.c_proj.weight\n",
      "h.9.attn.c_proj.bias\n",
      "h.9.ln_2.weight\n",
      "h.9.ln_2.bias\n",
      "h.9.mlp.c_fc.weight\n",
      "h.9.mlp.c_fc.bias\n",
      "h.9.mlp.c_proj.weight\n",
      "h.9.mlp.c_proj.bias\n",
      "h.10.ln_1.weight\n",
      "h.10.ln_1.bias\n",
      "h.10.attn.c_attn.weight\n",
      "h.10.attn.c_attn.bias\n",
      "h.10.attn.c_proj.weight\n",
      "h.10.attn.c_proj.bias\n",
      "h.10.ln_2.weight\n",
      "h.10.ln_2.bias\n",
      "h.10.mlp.c_fc.weight\n",
      "h.10.mlp.c_fc.bias\n",
      "h.10.mlp.c_proj.weight\n",
      "h.10.mlp.c_proj.bias\n",
      "h.11.ln_1.weight\n",
      "h.11.ln_1.bias\n",
      "h.11.attn.c_attn.weight\n",
      "h.11.attn.c_attn.bias\n",
      "h.11.attn.c_proj.weight\n",
      "h.11.attn.c_proj.bias\n",
      "h.11.ln_2.weight\n",
      "h.11.ln_2.bias\n",
      "h.11.mlp.c_fc.weight\n",
      "h.11.mlp.c_fc.bias\n",
      "h.11.mlp.c_proj.weight\n",
      "h.11.mlp.c_proj.bias\n",
      "ln_f.weight\n",
      "ln_f.bias\n"
     ]
    }
   ],
   "source": [
    "for el in pretrained.named_parameters():\n",
    "    print(el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MLP' from 'gpt2.model' (/home/gerold/projects/gpt2-all-in/gpt2/model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73612/3774767811.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MLP' from 'gpt2.model' (/home/gerold/projects/gpt2-all-in/gpt2/model.py)"
     ]
    }
   ],
   "source": [
    "from gpt2.model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gpt2.model' has no attribute 'CausalSelfAttention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73612/4052747370.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCausalSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPT2Config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gpt2.model' has no attribute 'CausalSelfAttention'"
     ]
    }
   ],
   "source": [
    "attn = gpt2.model.CausalSelfAttention(gpt2.config.GPT2Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = t.tril(t.ones(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = t.randn(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5514e-01, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05,\n",
       "         -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [ 1.4752e+00,  1.9423e+00, -1.0000e+05, -1.0000e+05, -1.0000e+05,\n",
       "         -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [ 2.7961e-01, -7.6509e-01, -1.8800e+00, -1.0000e+05, -1.0000e+05,\n",
       "         -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [-2.6870e-01,  9.1219e-01, -7.0824e-01,  9.7453e-01, -1.0000e+05,\n",
       "         -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [ 4.1186e-03, -7.5786e-01,  1.3436e+00,  1.1266e+00,  8.9082e-01,\n",
       "         -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [-3.2767e-01, -1.1534e-01, -1.1756e+00,  7.5173e-02,  1.5129e-01,\n",
       "         -3.0663e-01, -1.0000e+05, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [-4.4853e-01, -1.3076e+00,  7.4041e-01, -4.8402e-01,  6.1193e-02,\n",
       "         -2.1940e+00, -6.8383e-01, -1.0000e+05, -1.0000e+05, -1.0000e+05],\n",
       "        [-1.6216e+00,  6.2856e-01,  5.6010e-01,  6.2456e-01, -5.7096e-01,\n",
       "          9.5744e-02, -1.1576e+00, -6.2795e-01, -1.0000e+05, -1.0000e+05],\n",
       "        [ 1.1437e+00, -8.5750e-01,  6.5493e-01,  1.2842e+00,  4.7987e-02,\n",
       "          2.5418e-01,  4.1366e-01, -3.1750e-01, -7.4921e-01, -1.0000e+05],\n",
       "        [-9.9948e-01,  1.7601e-01, -2.9851e-01,  1.7658e-01, -1.6211e+00,\n",
       "          6.7586e-01, -6.7204e-01,  1.1641e+00,  4.1785e-01,  5.1010e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.masked_fill(mask == 0, -1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2-all-in-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
